{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "import mediapipe as mp \n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection \n",
    "\n",
    "def detect_face_mp(image):\n",
    "    with mp_face_detection.FaceDetection(min_detection_confidence=0.1) as face_detection:\n",
    "        # Convert to RGB\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process and get face detections\n",
    "        results = face_detection.process(rgb_image)\n",
    "        faces = []\n",
    "        \n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, _ = image.shape\n",
    "                x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                faces.append([x, y, w, h])\n",
    "        return faces\n",
    "\n",
    "\n",
    "\n",
    "import face_recognition\n",
    "\n",
    "def detect_face_fc(image):\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB as face_recognition expects RGB images\n",
    "    face_locations = face_recognition.face_locations(rgb_image)\n",
    "\n",
    "    faces = []\n",
    "    for (top, right, bottom, left) in face_locations:\n",
    "        faces.append([left, top, right - left, bottom - top])\n",
    "        \n",
    "    return faces\n",
    "\n",
    "\n",
    "def detect_face_cv(image):\n",
    "    net = cv2.dnn.readNetFromCaffe(\"models/face/deploy.prototxt\", \"models/face/res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "    h, w = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    \n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    \n",
    "    faces = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:  # you can adjust this threshold\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            faces.append([startX, startY, endX-startX, endY-startY])\n",
    "\n",
    "    return faces\n",
    "\n",
    "\n",
    "def apply_transformations(depth_image):\n",
    "    depth_image = np.nan_to_num(depth_image, nan=0.0)  # Replace NaNs with 0\n",
    "    depth_image[depth_image > 1.3] = 0  # Thresholding\n",
    "    \n",
    "    non_zero_indices = np.nonzero(depth_image)\n",
    "    if non_zero_indices[0].size > 0:\n",
    "        min_val = np.min(depth_image[non_zero_indices])  # Ignore zeros\n",
    "        max_val = np.max(depth_image)\n",
    "        \n",
    "        depth_image[non_zero_indices] = (depth_image[non_zero_indices] - min_val) / (max_val - min_val)  # Normalization\n",
    "    \n",
    "    depth_image = np.power(depth_image, 1.5)  # Gamma correction\n",
    "    \n",
    "    depth_image = 1 - depth_image  # Invert the depth image so that less depth appears lighter\n",
    "\n",
    "    return depth_image\n",
    "\n",
    "\n",
    "def find_max_indices(folder_path):\n",
    "    max_x_index = max_y_index = -1\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):\n",
    "                depth_data = np.load(os.path.join(root, file))\n",
    "                cur_max_x_index = depth_data.shape[1] - 1\n",
    "                cur_max_y_index = depth_data.shape[0] - 1\n",
    "                max_x_index = max(max_x_index, cur_max_x_index)\n",
    "                max_y_index = max(max_y_index, cur_max_y_index)\n",
    "\n",
    "    return max_x_index, max_y_index\n",
    "\n",
    "def pad_depth_arrays(input_folder, output_folder, max_x_index, max_y_index):\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):\n",
    "                depth_data = np.load(os.path.join(root, file))\n",
    "                depth_data[np.isnan(depth_data)] = 0 # convert nan values to 0\n",
    "                depth_data[(depth_data > 1.4)] = 0   # Applying threshold\n",
    "                target_shape = (158, 155)\n",
    "\n",
    "                padded_depth_data = np.pad(\n",
    "                    depth_data,\n",
    "                    ((0, target_shape[0] - depth_data.shape[0]), (0, target_shape[1] - depth_data.shape[1])),\n",
    "                    mode='constant', constant_values=0\n",
    "                )\n",
    "\n",
    "                rel_path = os.path.relpath(root, input_folder)\n",
    "                output_subfolder = os.path.join(output_folder, rel_path)\n",
    "                \n",
    "                try:\n",
    "                    os.makedirs(output_subfolder, exist_ok=True)\n",
    "                    print(f\"Successfully created the directory {output_subfolder}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to create directory. Error: {e}\")\n",
    "\n",
    "                output_file = os.path.join(output_subfolder, file)\n",
    "                np.save(output_file, padded_depth_data)\n",
    "\n",
    "\n",
    "def read_txt_to_depth_image_fd(file_path, width, height):\n",
    "    depth_image = np.zeros((height, width))\n",
    "    with open(file_path, 'r') as f:\n",
    "        next(f)  # Skip header line\n",
    "        for line in f:\n",
    "            i, j, x, y, z, _, _ = map(float, line.strip().split('\\t'))\n",
    "            if 0 <= int(i) < width and 0 <= int(j) < height:\n",
    "                depth_image[int(j), int(i)] = z\n",
    "    return depth_image\n",
    "\n",
    "\n",
    "\n",
    "def read_txt_to_depth_image_tr(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()[1:]  # Skip the header line\n",
    "        depth_image = np.loadtxt(lines)\n",
    "    return depth_image\n",
    "\n",
    "\n",
    "def read_txt_to_depth_array_np(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()[1:]  # Skip the header line\n",
    "        depth_data = np.loadtxt(lines)\n",
    "    return depth_data\n",
    "\n",
    "\n",
    "def perform_first_code_actions(person_dir, final_depth_folder):\n",
    "    for filename in os.listdir(person_dir):\n",
    "        if filename.endswith('_data.txt'):\n",
    "            person, file_number = map(int, filename.split('_')[:2])\n",
    "            print(f\"Processing person {person} file number {file_number}\")\n",
    "            input_text_path = os.path.join(person_dir, filename)\n",
    "            depth_data = read_txt_to_depth_array_np(input_text_path)\n",
    "            if not os.path.exists(final_depth_folder):\n",
    "                os.makedirs(final_depth_folder)\n",
    "            output_data_path = os.path.join(final_depth_folder, f\"{str(person).zfill(3)}_{str(file_number).zfill(2)}_depth_data.npy\")\n",
    "            np.save(output_data_path, depth_data)\n",
    "\n",
    "\n",
    "def print_padded_arrays(output_folder):\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(output_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):\n",
    "                padded_depth_data = np.load(os.path.join(root, file))\n",
    "                print(f'Array from File: {os.path.join(root, file)}')\n",
    "                print(f'Shape: {padded_depth_data.shape}')\n",
    "                count += 1\n",
    "    print(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping RGB facial data onto Depth Data\n",
    "### Attempt face detection using libraries : face_recongiton -> Mediapipe -> OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person: 007  image: 8\n",
      "depth path: test_data/test5_output/007/007_08_cloud.txt rgb_file_path: test_data/test5_output/007/007_08_image.png\n",
      "person: 010  image: 8\n",
      "depth path: test_data/test5_output/010/010_08_cloud.txt rgb_file_path: test_data/test5_output/010/010_08_image.png\n",
      "person: 018  image: 8\n",
      "depth path: test_data/test5_output/018/018_08_cloud.txt rgb_file_path: test_data/test5_output/018/018_08_image.png\n",
      "person: 017  image: 8\n",
      "depth path: test_data/test5_output/017/017_08_cloud.txt rgb_file_path: test_data/test5_output/017/017_08_image.png\n",
      "person: 001  image: 8\n",
      "depth path: test_data/test5_output/001/001_08_cloud.txt rgb_file_path: test_data/test5_output/001/001_08_image.png\n",
      "person: 003  image: 8\n",
      "depth path: test_data/test5_output/003/003_08_cloud.txt rgb_file_path: test_data/test5_output/003/003_08_image.png\n",
      "person: 005  image: 8\n",
      "depth path: test_data/test5_output/005/005_08_cloud.txt rgb_file_path: test_data/test5_output/005/005_08_image.png\n",
      "person: 013  image: 8\n",
      "depth path: test_data/test5_output/013/013_08_cloud.txt rgb_file_path: test_data/test5_output/013/013_08_image.png\n",
      "person: 011  image: 8\n",
      "depth path: test_data/test5_output/011/011_08_cloud.txt rgb_file_path: test_data/test5_output/011/011_08_image.png\n",
      "person: 014  image: 8\n",
      "depth path: test_data/test5_output/014/014_08_cloud.txt rgb_file_path: test_data/test5_output/014/014_08_image.png\n",
      "person: 008  image: 8\n",
      "depth path: test_data/test5_output/008/008_08_cloud.txt rgb_file_path: test_data/test5_output/008/008_08_image.png\n",
      "person: 015  image: 8\n",
      "depth path: test_data/test5_output/015/015_08_cloud.txt rgb_file_path: test_data/test5_output/015/015_08_image.png\n",
      "person: 012  image: 8\n",
      "depth path: test_data/test5_output/012/012_08_cloud.txt rgb_file_path: test_data/test5_output/012/012_08_image.png\n",
      "person: 002  image: 8\n",
      "depth path: test_data/test5_output/002/002_08_cloud.txt rgb_file_path: test_data/test5_output/002/002_08_image.png\n",
      "person: 000  image: 8\n",
      "depth path: test_data/test5_output/000/000_08_cloud.txt rgb_file_path: test_data/test5_output/000/000_08_image.png\n",
      "person: 009  image: 8\n",
      "depth path: test_data/test5_output/009/009_08_cloud.txt rgb_file_path: test_data/test5_output/009/009_08_image.png\n",
      "person: 006  image: 8\n",
      "depth path: test_data/test5_output/006/006_08_cloud.txt rgb_file_path: test_data/test5_output/006/006_08_image.png\n",
      "person: 004  image: 8\n",
      "depth path: test_data/test5_output/004/004_08_cloud.txt rgb_file_path: test_data/test5_output/004/004_08_image.png\n",
      "person: 016  image: 8\n",
      "depth path: test_data/test5_output/016/016_08_cloud.txt rgb_file_path: test_data/test5_output/016/016_08_image.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming detect_face_fc() and detect_face_mp() are defined elsewhere\n",
    "\n",
    "\n",
    "my_test = \"test5\"\n",
    "\n",
    "depth_width, depth_height = 960, 540\n",
    "rgb_width, rgb_height = 1920, 1080\n",
    "\n",
    "depth_folder = f'test_data/{my_test}_output'\n",
    "people_dirs = [os.path.join(depth_folder, d) for d in os.listdir(depth_folder) if os.path.isdir(os.path.join(depth_folder, d))]\n",
    "\n",
    "for person_dir in people_dirs:\n",
    "    person = os.path.basename(person_dir)\n",
    "    depth_files = [f for f in os.listdir(person_dir) if f.endswith('_cloud.txt')]\n",
    "    \n",
    "    for depth_file in depth_files:\n",
    "        file_number_str = depth_file.split('_')[1]\n",
    "        file_number = int(file_number_str)\n",
    "\n",
    "        print(f\"person: {person}  image: {file_number}\")\n",
    "\n",
    "        depth_file_path = os.path.join(person_dir, depth_file)\n",
    "        rgb_file_path = f'test_data/{my_test}_output/{person}/{person}_{str(file_number).zfill(2)}_image.png'\n",
    "        \n",
    "        print(\"depth path: \" + str(depth_file_path) + \" rgb_file_path: \" + str(rgb_file_path))\n",
    "\n",
    "        if not os.path.exists(depth_file_path) or not os.path.exists(rgb_file_path):\n",
    "            continue\n",
    "\n",
    "        depth_image = read_txt_to_depth_image_fd(depth_file_path, depth_width, depth_height)\n",
    "        rgb_image = cv2.imread(rgb_file_path)\n",
    "\n",
    "        faces = detect_face_fc(rgb_image)\n",
    "        if len(faces) == 0:\n",
    "            faces = detect_face_mp(rgb_image)\n",
    "            if len(faces) == 0:\n",
    "                continue\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cropped_rgb_face = rgb_image[y:y+h, x:x+w]\n",
    "\n",
    "            # Save cropped RGB face image\n",
    "            output_rgb_dir = f'test_data/{my_test}_face_result/{person}'\n",
    "            if not os.path.exists(output_rgb_dir):\n",
    "                os.makedirs(output_rgb_dir)\n",
    "            cv2.imwrite(f\"{output_rgb_dir}/{person}_{str(file_number).zfill(2)}_rgb.png\", cropped_rgb_face)\n",
    "        \n",
    "        scale_x, scale_y = depth_width / rgb_width, depth_height / rgb_height\n",
    "        x, y, w, h = int(x * scale_x), int(y * scale_y), int(w * scale_x), int(h * scale_y)\n",
    "        face_region_depth = depth_image[y:y+h, x:x+w]\n",
    "\n",
    "        output_dir = f'test_data/{my_test}_face_result/{person}'\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        output_text_path = f\"{output_dir}/{str(person).zfill(3)}_{str(file_number).zfill(2)}_data.txt\"\n",
    "\n",
    "        # Save the text file with resized values\n",
    "        with open(output_text_path, 'w') as f:\n",
    "            f.write(\"z-values for each (x, y) in a 2D grid\\n\")\n",
    "            for j in range(face_region_depth.shape[0]):  # Vertical (y-axis)\n",
    "                for i in range(face_region_depth.shape[1]):  # Horizontal (x-axis)\n",
    "                    z_value = face_region_depth[j, i]\n",
    "                    f.write(f\"{z_value}\\t\")\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "        output_depth_face = f'test_data/{my_test}_face_result/{person}'\n",
    "        if not os.path.exists(output_depth_face):\n",
    "            os.makedirs(output_depth_face)\n",
    "        #plt.imsave(f\"{output_depth_face}/{str(person).zfill(3)}_{str(file_number).zfill(2)}_depth.png\", face_region_depth, cmap='gray')\n",
    "\n",
    "        depth_image = read_txt_to_depth_image_tr(output_text_path)\n",
    "        transformed_depth_image = apply_transformations(depth_image)\n",
    "        \n",
    "        # Save the transformed depth image\n",
    "        output_image_path = os.path.join(output_depth_face, f\"{str(person).zfill(3)}_{str(file_number).zfill(2)}_depth.png\")\n",
    "        plt.imsave(output_image_path, transformed_depth_image, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Check face detection results in results in <b>face_result</b> folder.\n",
    "<p>If files are missing use <b>\"bouding_box.py\"</b> to manually select face region for a specific file.<b>(Recommended)</b></p>\n",
    "<p>You can also use <b>\"face_detector_fix.py\"</b> to test out different face detectors.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Numpy Arrays, add Padding, and apply Threshold\n",
    "#### Transform (y, x) => (158, 155)\n",
    "#### Threshold => Depth values > 1.3 = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data/test5_depth_numpy\n",
      "Processing person 8 file number 8\n",
      "Processing person 6 file number 8\n",
      "Processing person 4 file number 8\n",
      "Successfully created the directory test_data/test5_padded_depth_numpy/008\n",
      "Successfully created the directory test_data/test5_padded_depth_numpy/006\n",
      "Successfully created the directory test_data/test5_padded_depth_numpy/004\n",
      "Array from File: test_data/test5_padded_depth_numpy/008/008_08_depth_data.npy\n",
      "Shape: (158, 155)\n",
      "Array from File: test_data/test5_padded_depth_numpy/006/006_08_depth_data.npy\n",
      "Shape: (158, 155)\n",
      "Array from File: test_data/test5_padded_depth_numpy/004/004_08_depth_data.npy\n",
      "Shape: (158, 155)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "use_padding = True\n",
    "\n",
    "my_test = \"test5\"\n",
    "root_folder = f'test_data/{my_test}_face_result'\n",
    "input_folder = os.path.join('test_data', f'{my_test}_depth_numpy')\n",
    "print(input_folder)\n",
    "\n",
    "\n",
    "if use_padding:\n",
    "    output_folder = os.path.join('test_data', f'{my_test}_padded_depth_numpy')\n",
    "else:\n",
    "    output_folder = os.path.join('test_data', f'{my_test}_depth_numpy')\n",
    "\n",
    "people_dirs = [os.path.join(root_folder, d) for d in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, d))]\n",
    "\n",
    "for person_dir in people_dirs:\n",
    "    person = os.path.basename(person_dir)\n",
    "    final_depth_folder = os.path.join('test_data', f\"{my_test}_depth_numpy\", str(person))\n",
    "    perform_first_code_actions(person_dir, final_depth_folder)\n",
    "\n",
    "if use_padding:\n",
    "    max_x_index, max_y_index = find_max_indices(input_folder)\n",
    "    pad_depth_arrays(input_folder, output_folder, max_x_index, max_y_index)\n",
    "\n",
    "\n",
    "print_padded_arrays(output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h3>Your data is now for training/testing and is stored in <b>__padded_depth_numpy</b></h3>\n",
    "<h5>You can now move to <b>train_test.ipynb</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
